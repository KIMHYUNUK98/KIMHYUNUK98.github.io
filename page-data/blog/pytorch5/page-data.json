{
    "componentChunkName": "component---src-templates-blog-post-tsx",
    "path": "/blog/pytorch5/",
    "result": {"data":{"markdownRemark":{"html":"<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 68.71165644171779%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIBBf/EABUBAQEAAAAAAAAAAAAAAAAAAAEA/9oADAMBAAIQAxAAAAHpIlKab//EABoQAAMAAwEAAAAAAAAAAAAAAAABEgIDESH/2gAIAQEAAQUCrZ2tpDyK9tizZ//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oACAEDAQE/AUf/xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAgEBPwGq/8QAGRAAAgMBAAAAAAAAAAAAAAAAApEAETIg/9oACAEBAAY/Asi5kXLIBfH/xAAbEAEAAgIDAAAAAAAAAAAAAAABABEhMWFxkf/aAAgBAQABPyFtBR3gWvZLLcPKLvghkwSpon//2gAMAwEAAgADAAAAEJ8P/8QAFREBAQAAAAAAAAAAAAAAAAAAABH/2gAIAQMBAT8QiH//xAAWEQEBAQAAAAAAAAAAAAAAAAAAEXH/2gAIAQIBAT8Qwt//xAAeEAACAgEFAQAAAAAAAAAAAAAAAREhMUFhcZHR4f/aAAgBAQABPxBV5ycN2roTOksz4ktZ2fgSzcG1ydRa+Q//2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/384a2192de7d7053adb214d2e71a6239/6aca1/pytorch5.jpg\"\n        srcset=\"/static/384a2192de7d7053adb214d2e71a6239/d2f63/pytorch5.jpg 163w,\n/static/384a2192de7d7053adb214d2e71a6239/c989d/pytorch5.jpg 325w,\n/static/384a2192de7d7053adb214d2e71a6239/6aca1/pytorch5.jpg 650w,\n/static/384a2192de7d7053adb214d2e71a6239/bf093/pytorch5.jpg 888w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3>PyTorch vs TensorFlow</h3>\n<p>Tensorflow이전에는 쓰기 어려운 라이브러리를 전문가들이 사용했다면 이를 통해 굉장히 쉽게 접근이 가능하게 됐다. PyTorch는 Tensorflow보다 늦게 나왔고 더 쉽게 만들어졌다. <strong>신경망을 시각화하는 TensorBoard는 둘다 사용이 가능한데 약간의 trick</strong>을 사용한다.</p>\n<p>TensorFlow는 Static하다. 그래프 구조가 고정되어 있다. 여기서 실제 연산이 되는 것은 Propagation을 할 때 Branch First Search 를 따르게 된다. 그러므로 순차적 계산이 자동적으로 되게 된다. 고정된 그래프를 먼저 만들고 연산을 수행한다. <strong>반면 PyTorch의 경우 연산이 이루어지면서 동시에 Computation Graph가 만들어진다.</strong></p>\n<hr>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 67.48466257668711%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAMBAgQF/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAe3bNA0SWf/EABoQAQACAwEAAAAAAAAAAAAAAAEAEgIDEBH/2gAIAQEAAQUC846sFuy7LM//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAWEQEBAQAAAAAAAAAAAAAAAAAAARH/2gAIAQIBAT8BbX//xAAXEAEAAwAAAAAAAAAAAAAAAAABEBEg/9oACAEBAAY/AotMf//EABoQAAICAwAAAAAAAAAAAAAAAAABEWEQQaH/2gAIAQEAAT8hbSKVro9S27L8t//aAAwDAQACAAMAAAAQk9//xAAWEQEBAQAAAAAAAAAAAAAAAAAAARH/2gAIAQMBAT8QZH//xAAVEQEBAAAAAAAAAAAAAAAAAAAAYf/aAAgBAgEBPxBR/8QAGxABAAMBAAMAAAAAAAAAAAAAAQARIVFBcdH/2gAIAQEAAT8QuEqvb9lCiAdNSqigxsbh4nal7P/Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/df73e87a9b8997c0289a395d891b4a7e/6aca1/pytorch6.jpg\"\n        srcset=\"/static/df73e87a9b8997c0289a395d891b4a7e/d2f63/pytorch6.jpg 163w,\n/static/df73e87a9b8997c0289a395d891b4a7e/c989d/pytorch6.jpg 325w,\n/static/df73e87a9b8997c0289a395d891b4a7e/6aca1/pytorch6.jpg 650w,\n/static/df73e87a9b8997c0289a395d891b4a7e/52bdb/pytorch6.jpg 895w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3>Computational Graph</h3>\n<p>Neural Network는 Computational Graph로 표현이 된다. (b)에서 시그마가 안들어간 이유는 <strong>벡터인 경우에는 시그마를 쓰지 않는다.</strong></p>\n<hr>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 67.48466257668711%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAEDBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHcbRMsWf/EABoQAAICAwAAAAAAAAAAAAAAAAABAhEDEEH/2gAIAQEAAQUCoQ8UG+1r/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFhEBAQEAAAAAAAAAAAAAAAAAAAER/9oACAECAQE/AW1//8QAFxABAAMAAAAAAAAAAAAAAAAAARARIP/aAAgBAQAGPwKLTH//xAAaEAACAgMAAAAAAAAAAAAAAAAAAREhEDFh/9oACAEBAAE/IXbZwOUlsaoQx//aAAwDAQACAAMAAAAQy9//xAAWEQEBAQAAAAAAAAAAAAAAAAAAARH/2gAIAQMBAT8QZH//xAAVEQEBAAAAAAAAAAAAAAAAAAAAYf/aAAgBAgEBPxBR/8QAHRABAQACAQUAAAAAAAAAAAAAAREAMRAhQXHB0f/aAAgBAQABPxCWgtdP3IAETffBbbSrlvA+sAI16Bx//9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/63ba6e4215e46751a30ce23974d7ac02/6aca1/pytorch7.jpg\"\n        srcset=\"/static/63ba6e4215e46751a30ce23974d7ac02/d2f63/pytorch7.jpg 163w,\n/static/63ba6e4215e46751a30ce23974d7ac02/c989d/pytorch7.jpg 325w,\n/static/63ba6e4215e46751a30ce23974d7ac02/6aca1/pytorch7.jpg 650w,\n/static/63ba6e4215e46751a30ce23974d7ac02/52bdb/pytorch7.jpg 895w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3>MultiLayer Perceptron</h3>\n<p>MultiLayer Perceptron은 하나의 층이 있지만 현재 layer의 규칙이 깨졌다. 중간에 건너뛰는 것이 가능해졌다는 것이다. 전통적으로 신경망은 Array라고 헀지만 <strong>일반적인 Graph의 형태를 NN이 가질 수 있다.</strong> Self Link Node가 될 수도 있고 굉장히 다양하다. <u>Layer의 Array로 구현할 수 없는 Computation Graph로 표현할 수 있다.</u></p>\n<hr>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 65.03067484662577%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAMCBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe40JLD/xAAaEAACAgMAAAAAAAAAAAAAAAAAAgEQEyEx/9oACAEBAAEFAtHDGjVNf//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABYRAQEBAAAAAAAAAAAAAAAAAAABEf/aAAgBAgEBPwFtf//EABcQAQADAAAAAAAAAAAAAAAAAAEQESD/2gAIAQEABj8Ci0x//8QAGhAAAgMBAQAAAAAAAAAAAAAAAAERITEQYf/aAAgBAQABPyF2wlYQ2LrfpFiTz//aAAwDAQACAAMAAAAQoO//xAAWEQEBAQAAAAAAAAAAAAAAAAAAARH/2gAIAQMBAT8QjI//xAAWEQEBAQAAAAAAAAAAAAAAAAAAAWH/2gAIAQIBAT8QrR//xAAZEAEAAwEBAAAAAAAAAAAAAAABABExIVH/2gAIAQEAAT8QARq72KDVL4xVoCqiW1spcQbO14wAwqf/2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/c78e7ea25221d95f7af95e924b3ec090/6aca1/pytorch8.jpg\"\n        srcset=\"/static/c78e7ea25221d95f7af95e924b3ec090/d2f63/pytorch8.jpg 163w,\n/static/c78e7ea25221d95f7af95e924b3ec090/c989d/pytorch8.jpg 325w,\n/static/c78e7ea25221d95f7af95e924b3ec090/6aca1/pytorch8.jpg 650w,\n/static/c78e7ea25221d95f7af95e924b3ec090/a92c5/pytorch8.jpg 883w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3>Dynamic Graph of PyTorch</h3>\n<p>그 순간에 다이나믹하게 Node가 만들어진다. 동일한 Layer를 계속 반복하고 싶을 때가 있다고 가정해보면 고정된 그래프에서는 힘듦을 알 수 있다. 이 경우 루프의 연산을 하면서 해당 그래프만 그리면 빠르게 수행할 수 있다는 것이다. <strong>Static 보다 Dynamic함이 더 연산에 효율적이라는 것이다.</strong></p>\n<hr>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 65.03067484662577%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIDBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHbZXJFyz//xAAbEAABBAMAAAAAAAAAAAAAAAABAAIDERAhQf/aAAgBAQABBQKt0jEwnox//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFhEBAQEAAAAAAAAAAAAAAAAAAAER/9oACAECAQE/AW1//8QAFxABAAMAAAAAAAAAAAAAAAAAARARIP/aAAgBAQAGPwKLTH//xAAYEAEBAQEBAAAAAAAAAAAAAAABABEQIf/aAAgBAQABPyFgrrSsvqWm8//aAAwDAQACAAMAAAAQkx//xAAWEQEBAQAAAAAAAAAAAAAAAAAAARH/2gAIAQMBAT8QZH//xAAVEQEBAAAAAAAAAAAAAAAAAAAAYf/aAAgBAgEBPxBR/8QAHBABAQEAAQUAAAAAAAAAAAAAAREAECExQVGB/9oACAEBAAE/EKIDu+R0JQfrg5uqq4ugJPWhxLx//9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/8be1ded2d62f0e44b4e1e8dfb53ed160/6aca1/pytorch9.jpg\"\n        srcset=\"/static/8be1ded2d62f0e44b4e1e8dfb53ed160/d2f63/pytorch9.jpg 163w,\n/static/8be1ded2d62f0e44b4e1e8dfb53ed160/c989d/pytorch9.jpg 325w,\n/static/8be1ded2d62f0e44b4e1e8dfb53ed160/6aca1/pytorch9.jpg 650w,\n/static/8be1ded2d62f0e44b4e1e8dfb53ed160/a92c5/pytorch9.jpg 883w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3>Neural Network</h3>\n<p>단순한 MLP만을 제공하는 사이키런과는 달리 <strong>PyTorch는 굉장히 복잡한 연산을 가능하게 해준다.</strong> PyTorch는 Neural Net의 다양한 Network를 사용할 수 있게 해준다. PyTorch로 Neural Net을 사용하는 방법은 다음과 같은 스텝을 가진다.</p>\n<ol>\n<li>\n<p>맨 처음 Neural Net을 정의해야 하는데 Class를 정의함으로서 정의할 수 있다.</p>\n</li>\n<li>\n<p>두 번째로 Data를 읽어올 준비를 해야한다. 일정한 개수만큼 잘라서 Trainer한테 넣어주는 역할을 한다.</p>\n</li>\n<li>\n<p>세 번째로 학습을 하는데, 크게 3단계로 이루어진다. <strong>Gradient 계산을 하고 현재의 Weight를 최신화하는 두 가지 과정을 거쳐야 한다.</strong></p>\n</li>\n</ol>\n<p>Back Propagation의 과정이 Gradient를 구하는 단계가 되고 Update weight를 하는 것은 Weight를 말그대로 최신화 시켜주는 것이다. <u>Forward 에서 Output 결과를 계산하고 Back에서 Gradient를 계산하는 과정을 계속 반복하게 된다.</u> 마지막으로 만들어낸 모델을 4번째에서 사용을 하는 것이다.</p>\n<hr>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 71.16564417177914%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAECBAX/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAwDAQACEAMQAAAB7bckGgs//8QAGRAAAwADAAAAAAAAAAAAAAAAAAECAxAR/9oACAEBAAEFAjo8MU3v/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFhEBAQEAAAAAAAAAAAAAAAAAAAER/9oACAECAQE/AW1//8QAFxABAAMAAAAAAAAAAAAAAAAAARARIP/aAAgBAQAGPwKLTH//xAAbEAACAQUAAAAAAAAAAAAAAAAAARARITFBcf/aAAgBAQABPyFq5wOlW2aizH//2gAMAwEAAgADAAAAEMMf/8QAFhEBAQEAAAAAAAAAAAAAAAAAAAER/9oACAEDAQE/EGR//8QAFREBAQAAAAAAAAAAAAAAAAAAAGH/2gAIAQIBAT8QWf/EABwQAQACAgMBAAAAAAAAAAAAAAEAESFxEDFRwf/aAAgBAQABPxBh31tPsKlW8MwijrVWG4GG+P/Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/acbd6a834e93ff8f194c8609af489498/6aca1/pytorch10.jpg\"\n        srcset=\"/static/acbd6a834e93ff8f194c8609af489498/d2f63/pytorch10.jpg 163w,\n/static/acbd6a834e93ff8f194c8609af489498/c989d/pytorch10.jpg 325w,\n/static/acbd6a834e93ff8f194c8609af489498/6aca1/pytorch10.jpg 650w,\n/static/acbd6a834e93ff8f194c8609af489498/3981f/pytorch10.jpg 889w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>필기 숫자 데이터를 가지고 학습을 시킨다.</p>\n<hr>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 70.5521472392638%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAMCBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHuaCK6z//EABcQAAMBAAAAAAAAAAAAAAAAAAECEAP/2gAIAQEAAQUChzRjf//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABYRAQEBAAAAAAAAAAAAAAAAAAABEf/aAAgBAgEBPwFtf//EABcQAQADAAAAAAAAAAAAAAAAAAEQESD/2gAIAQEABj8Ci0x//8QAGRABAQEAAwAAAAAAAAAAAAAAAQARECEx/9oACAEBAAE/IUxtnOhZ7cn3j//aAAwDAQACAAMAAAAQwx//xAAWEQEBAQAAAAAAAAAAAAAAAAAAARH/2gAIAQMBAT8QZH//xAAVEQEBAAAAAAAAAAAAAAAAAAAAYf/aAAgBAgEBPxBR/8QAHBABAAICAwEAAAAAAAAAAAAAAQARIVExQWGh/9oACAEBAAE/EKzsXaSw0n2OG5TcwdMxUDyU+T//2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/9f94e30276d994a2122116c5dcca9f5d/6aca1/pytorch11.jpg\"\n        srcset=\"/static/9f94e30276d994a2122116c5dcca9f5d/d2f63/pytorch11.jpg 163w,\n/static/9f94e30276d994a2122116c5dcca9f5d/c989d/pytorch11.jpg 325w,\n/static/9f94e30276d994a2122116c5dcca9f5d/6aca1/pytorch11.jpg 650w,\n/static/9f94e30276d994a2122116c5dcca9f5d/a92c5/pytorch11.jpg 883w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3>Multi Layer Perceptron</h3>\n<p>함수 정의와 클래스 정의하는 문법은 알고 있어야 한다. (굉장히 기본적인 파이썬 내용). 파이썬에서 상속을 받을 때 클래스를 정의할 때 파라미터에 상속받을 클래스 이름을 적어준다. 여기서는 <strong>nn.Module의 기능들을 상속</strong>받는다. 그렇다면 nn.Module은 무엇인가.</p>\n<p>이는 PyTorch가 제공하는 패키지이다. 이 클래스는 Nueral Network의 Module을 표현하기 위한 Super 클래스가 된다. 대부분의 기능을 nn.Module이 갖고 있기 때문에 이 클래스를 상속받는 이유이다.</p>\n<p><strong>init</strong> 은 컨스트럭터이다. Self는 현재 오브젝트 자기자신을 나타내는 변수이다. Input_size=784 는 28 x 28의 값이 된다. 즉, 입력 영상의 데이터 값이 되고 num_class의 경우 숫자가 0에서 9까지의 총 10개의 클래스가 된다.</p>\n<p><strong>Nn.Sequential은 연산에 필요한 Operator를 만드는 과정</strong>에 해당한다. Nn.Linear는 Weighted Sum을 계산하게 해준다. 입력크기와 출력 크기가 주어져야 한다. 여기서는 Input_size가 784고 출력은 64가 된다. 첫 번째 Layer의 Hidden Node의 개수가 64개가 된다. ReLU는 Activation Function에 해당한다. 계산 과정에서 Bias는 Linear Layer에 저장된다.</p>\n<p><strong>Classification 문제의 경우 <u>SoftMax Activation Function</u>을 사용한다.</strong> 하지만 학습을 안하는 경우에는 SoftMax를 사용하지 않아도 된다. <u>최대값을 갖는 관점에서는 SoftMax가 사용되지 않아도 된다. (인식하는 경우) SoftMax는 학습할 때 필요하다.</u> Cross Entropy를 사용하기 위해서 꼭 사용해야 하는데, 확률의 범위 안으로 들어가는 값으로 만들어줘야 하기 때문이다.</p>\n<p><strong>Sequential 클래스는 여러 개의 Layer를 일렬로 연결해주는 Container의 역할을 한다.</strong></p>\n<p>Forward 함수에서 x라는 입력값이 들어오면 x를 view라고 하는 함수에 집어넣는다. 일단 Batch의개념을 알아야 한다. 병렬처리의 이점을 최대로 살리기 위해 <strong>Training Sample을 동시적으로 넣게 되는데 병렬화가 많이 되면 GPU를 이용할 때 훨씬 빨라진다.</strong> Batch가 64개인 경우 28 x 28의 영상이 64개씩 들어온다. 실제 Dimention은 64D가 된다. 데이터가 64개 들어온다면 64D짜리가 64개 들어오게 되는 것이다. X의 크기는 (N,28,28) 이 된다.</p>\n<p>X의 타입은 Tensor이고 size() 를 하면 N번째 Dimention의 크기를 알려준다. <u>X.size(0)은 batch 크기를 가져오라는 것이다.</u> -1은 알아서 계산해달라는 것.  <strong>-1은 view 속에 딱 한 번만 사용할 수 있다.</strong> Size(0)은 배치 size(1)은 Width size(2)는 height가 된다. X_는 N 곱하기 784 Dimention으로 변환된 데이터이다. <strong>view라는 함수는 3차원 데이터를 2차원으로 바꿔줘야 한다. 2차원 데이터가 64개 있는  3차원을 2차원으로 바꿔주는 역할을 한다.</strong></p>\n<p>컨스트럭터에서 파라미터에 Call된 숫자는 Default Parameter이므로 괄호가 사용되지 않을 때 자동으로 해당 값이 들어가게 된다.</p>\n<hr>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 69.32515337423312%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAIBAwQF/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAe0zQUGks//EABkQAQACAwAAAAAAAAAAAAAAAAEAAgMQEf/aAAgBAQABBQJnWOKtlhr/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAWEQEBAQAAAAAAAAAAAAAAAAAAARH/2gAIAQIBAT8BbX//xAAYEAACAwAAAAAAAAAAAAAAAAABAhARIP/aAAgBAQAGPwKLK4//xAAZEAEAAgMAAAAAAAAAAAAAAAABABEQIVH/2gAIAQEAAT8hsLqHCNLSwZ//2gAMAwEAAgADAAAAEIPf/8QAFhEBAQEAAAAAAAAAAAAAAAAAAAER/9oACAEDAQE/EGR//8QAFREBAQAAAAAAAAAAAAAAAAAAAGH/2gAIAQIBAT8QWf/EAB0QAQADAAEFAAAAAAAAAAAAAAEAESFBEDFRcdH/2gAIAQEAAT8QBRYu7t+xDq9ReqtVZyZ47Suta89P/9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/d30258ba04eff9663b0a7e2c51a5d588/6aca1/pytorch12.jpg\"\n        srcset=\"/static/d30258ba04eff9663b0a7e2c51a5d588/d2f63/pytorch12.jpg 163w,\n/static/d30258ba04eff9663b0a7e2c51a5d588/c989d/pytorch12.jpg 325w,\n/static/d30258ba04eff9663b0a7e2c51a5d588/6aca1/pytorch12.jpg 650w,\n/static/d30258ba04eff9663b0a7e2c51a5d588/51568/pytorch12.jpg 882w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3>Convolutional Neural Network</h3>\n<p>nn이라는 곳에서 Loss Function을 불러서 쓸 수 있다. SGD의 경우 Gradient를 업데이트하는 단위가 batch가 된다. 첫 번째 파라미터는 net.parameter 인데 사용되는 <strong>net은 이전에 정의한 Model의 객체 변수</strong>이고</p>\n<p><u>parameters는 nn.Module 안에 들어있는 함수이다. 이 함수는 Weight 벡터를 List의 형태로 모아주는 함수이다.</u> <strong>즉, net.parameter 해당 벡터 데이터를 통째로 가져온다는 뜻이다.</strong></p>\n<hr>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 72.39263803680981%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAECAwX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHdYiJYH//EABkQAAIDAQAAAAAAAAAAAAAAAAEQAAIREv/aAAgBAQABBQLFxUwv/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFxAAAwEAAAAAAAAAAAAAAAAAARAgMv/aAAgBAQAGPwJZEf/EABkQAQACAwAAAAAAAAAAAAAAAAEQESBBYf/aAAgBAQABPyFBohdai8wf/9oADAMBAAIAAwAAABBT7//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oACAEDAQE/EEf/xAAWEQEBAQAAAAAAAAAAAAAAAAAAARH/2gAIAQIBAT8QbX//xAAYEAEBAQEBAAAAAAAAAAAAAAABABExUf/aAAgBAQABPxBHRN9CHZ44NV1cxi8jl//Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/fd149da4ce6a23755752bc21344dca95/6aca1/pytorch13.jpg\"\n        srcset=\"/static/fd149da4ce6a23755752bc21344dca95/d2f63/pytorch13.jpg 163w,\n/static/fd149da4ce6a23755752bc21344dca95/c989d/pytorch13.jpg 325w,\n/static/fd149da4ce6a23755752bc21344dca95/6aca1/pytorch13.jpg 650w,\n/static/fd149da4ce6a23755752bc21344dca95/d98c0/pytorch13.jpg 894w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3>Convolutional Neural Network</h3>\n<p>Trainloader라는 함수를 사용한다. 전체 데이터는 6만개이지만 여기에서는 64씩 데이터를 하나씩 쭉 제공하는 것이 trainloader 가 된다. <strong>Enumerate라는 함수는 해당 batch가 몇 번째 인지까지 정보를 받을 수 있다.</strong> 64개의 영상을 data로 받게 되면 64개의 input과 각각의 정답에 해당하는 label까지 저장이 된다.</p>\n<p>Optimizer.zero_grad는 Gradient는 Batch 단위 또는 그 이상의 단위에서 모아 업데이트를 하게 되는데 기존의 값이 있다면 더하는 로직으로 만들게 되어있다. <strong>Optimizer는 처음에 시작할 때 0으로 초기화를 해야하고,</strong> 업데이트가 끝났다면 이미 사용한 Gradient를 0으로 초기화를 해야 한다.</p>\n<p>Net(inputs)를 해주면 Forward 함수를 호출하게 된다. Criterion을 CrossEntropy로 정의를 했기 때문에 이를 사용해 ouputs과 label의 차이인 loss를 계산하게 된다. Loss.backward() 는 Back Propagation을 진행하게 된다. Loss에 대한 Back Propagation임을 주의하자. 다음으로 <strong>Optimizer.step인데, step이라는 함수는 Weight 업데이트를 해주는 함수가 된다.</strong></p>\n<hr>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 12.883435582822086%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAADABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB3KEB/8QAFBABAAAAAAAAAAAAAAAAAAAAEP/aAAgBAQABBQJ//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAEP/aAAgBAQAGPwJ//8QAFBABAAAAAAAAAAAAAAAAAAAAEP/aAAgBAQABPyF//9oADAMBAAIAAwAAABCAD//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABoQAQABBQAAAAAAAAAAAAAAAAEAEVFhgZH/2gAIAQEAAT8QoZ7NxCxP/9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/ba2b8fa0bf8fa718104dd53f28ee017e/6aca1/pytorch14.jpg\"\n        srcset=\"/static/ba2b8fa0bf8fa718104dd53f28ee017e/d2f63/pytorch14.jpg 163w,\n/static/ba2b8fa0bf8fa718104dd53f28ee017e/c989d/pytorch14.jpg 325w,\n/static/ba2b8fa0bf8fa718104dd53f28ee017e/6aca1/pytorch14.jpg 650w,\n/static/ba2b8fa0bf8fa718104dd53f28ee017e/65069/pytorch14.jpg 892w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>모델 저장하는 방법.</p>\n<hr>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 71.77914110429448%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAIBAwX/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAwDAQACEAMQAAAB2mIELyz/xAAYEAADAQEAAAAAAAAAAAAAAAABAhADQf/aAAgBAQABBQKHJGPZ/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFhEBAQEAAAAAAAAAAAAAAAAAAAER/9oACAECAQE/AW1//8QAFxABAAMAAAAAAAAAAAAAAAAAARARIP/aAAgBAQAGPwKLTH//xAAaEAEAAgMBAAAAAAAAAAAAAAABABEQITFh/9oACAEBAAE/IXsH0iiwuN0uiHJ//9oADAMBAAIAAwAAABDzH//EABYRAQEBAAAAAAAAAAAAAAAAAAABEf/aAAgBAwEBPxBkf//EABURAQEAAAAAAAAAAAAAAAAAAABh/9oACAECAQE/EFn/xAAaEAEAAwEBAQAAAAAAAAAAAAABABEhQVFx/9oACAEBAAE/EMsut7c5qfLl2faqynLSPvIpVm+TQaqf/9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/3fd2c7c366877212671cd9b369c53697/6aca1/pytorch15.jpg\"\n        srcset=\"/static/3fd2c7c366877212671cd9b369c53697/d2f63/pytorch15.jpg 163w,\n/static/3fd2c7c366877212671cd9b369c53697/c989d/pytorch15.jpg 325w,\n/static/3fd2c7c366877212671cd9b369c53697/6aca1/pytorch15.jpg 650w,\n/static/3fd2c7c366877212671cd9b369c53697/a92c5/pytorch15.jpg 883w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3>Tensor in PyTorch</h3>\n<p>PyTorch가 제공하는 <strong>자동 미분 기능을 Tensor가 지원하고 있다.</strong> Tensor가 무슨 타입인지 지정할 수 있게 되어있다. 여기서는 torch.float32라고 많이 사용하고 있는데 <strong>GPU는 float32에서 속도가 빠르게 처리된다.</strong></p>\n<p><u>List에 있는 value를 Tensor로 변환되는 FloatTensor를 사용할 수 있다. 많은 데이터가 리스트에 담겨있는데 이 방법은 PyTorch 안으로 데이터를 변환하기 위해 자주 사용되는 꼴이다.</u> Rand() 와 zeros() 등등도 존재한다. Rand는 0에서 1사이의 임의의 값을 출력</p>\n<p>Print(x+y) 에서 x와 y의 shape이 틀리면 <strong>BroadCasting 기능</strong>으로 자동 연산이 된다. X[;,1] 은 두 번째 Column이 된다. 이렇게 slicing을 하면 2차원 Tensor가 얻어지게 된다.</p>\n<p>Row차원이 콜론, 즉 Slicing이므로 차원이 줄지 않는다. Column은 Index이고 차원이 준다. <strong>콜론이라는 것은 모든 row 또는 모든 col에서 데이터를 가져오라는 뜻.</strong> 모든 row에 대해서 1번째 col을 가져오는 것.</p>\n<p>Torch.randn()에서 n은 Normal (평균이 0이고 분산이 0인 곳)상태에서 랜덤하게 주어지게 된다. Rand의 범위는 0과 1 사이가 되고 Randn은  -1에서 1 사이가 된다. -> 정규분포</p>\n<p>x.item()은 사이즈가 1인 Tensor의 value를 스칼라로 가져오는 함수!! 예를 들어 신경망에서 사이즈 1짜리 Tensor가 나왔다고 했을 때 그때의 값을 가져오고 싶을 때 item 함수를 사용한다.\r\nA가 텐서라면 numpy로 변환해주는 함수가 .numpy가 된다.</p>\n<hr>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 49.079754601226995%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAQBAgMF/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAe1bSBcYLP/EABcQAAMBAAAAAAAAAAAAAAAAAAECEAP/2gAIAQEAAQUChxRjf//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABYRAQEBAAAAAAAAAAAAAAAAAAABEf/aAAgBAgEBPwFtf//EABcQAQADAAAAAAAAAAAAAAAAAAEQESD/2gAIAQEABj8Ci0x//8QAGRABAQADAQAAAAAAAAAAAAAAAREAIFHx/9oACAEBAAE/IW33Je4sQr10/9oADAMBAAIAAwAAABCQ3//EABYRAQEBAAAAAAAAAAAAAAAAAAABEf/aAAgBAwEBPxBkf//EABURAQEAAAAAAAAAAAAAAAAAAABh/9oACAECAQE/EFn/xAAbEAEAAQUBAAAAAAAAAAAAAAABACAhMXHRof/aAAgBAQABPxAlgKb6gxn12MGK6lH/2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/5d1ac7d993562437989186b2d07a5d31/6aca1/pytorch16.jpg\"\n        srcset=\"/static/5d1ac7d993562437989186b2d07a5d31/d2f63/pytorch16.jpg 163w,\n/static/5d1ac7d993562437989186b2d07a5d31/c989d/pytorch16.jpg 325w,\n/static/5d1ac7d993562437989186b2d07a5d31/6aca1/pytorch16.jpg 650w,\n/static/5d1ac7d993562437989186b2d07a5d31/72f09/pytorch16.jpg 886w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3>Data Format for PyTorch</h3>\n<p>Batch는 한 덩어리에 들어오게 되는 데이터의 숫자. Convolution은 Layer자체가 3차원 구조를 가지고 channel, height, width의 데이터를 가진다. 한 데이터 마다 3차원의 구조를 가진다. RNN은 시간에 대한 축이 하나 더 들어간다.</p>\n<style class=\"grvsc-styles\">\n  .grvsc-container {\n    overflow: auto;\n    position: relative;\n    -webkit-overflow-scrolling: touch;\n    padding-top: 1rem;\n    padding-top: var(--grvsc-padding-top, var(--grvsc-padding-v, 1rem));\n    padding-bottom: 1rem;\n    padding-bottom: var(--grvsc-padding-bottom, var(--grvsc-padding-v, 1rem));\n    border-radius: 8px;\n    border-radius: var(--grvsc-border-radius, 8px);\n    font-feature-settings: normal;\n    line-height: 1.4;\n  }\n  \n  .grvsc-code {\n    display: table;\n  }\n  \n  .grvsc-line {\n    display: table-row;\n    box-sizing: border-box;\n    width: 100%;\n    position: relative;\n  }\n  \n  .grvsc-line > * {\n    position: relative;\n  }\n  \n  .grvsc-gutter-pad {\n    display: table-cell;\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  .grvsc-gutter {\n    display: table-cell;\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter::before {\n    content: attr(data-content);\n  }\n  \n  .grvsc-source {\n    display: table-cell;\n    padding-left: 1.5rem;\n    padding-left: var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem));\n    padding-right: 1.5rem;\n    padding-right: var(--grvsc-padding-right, var(--grvsc-padding-h, 1.5rem));\n  }\n  \n  .grvsc-source:empty::after {\n    content: ' ';\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter + .grvsc-source {\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  /* Line transformer styles */\n  \n  .grvsc-has-line-highlighting > .grvsc-code > .grvsc-line::before {\n    content: ' ';\n    position: absolute;\n    width: 100%;\n  }\n  \n  .grvsc-line-diff-add::before {\n    background-color: var(--grvsc-line-diff-add-background-color, rgba(0, 255, 60, 0.2));\n  }\n  \n  .grvsc-line-diff-del::before {\n    background-color: var(--grvsc-line-diff-del-background-color, rgba(255, 0, 20, 0.2));\n  }\n  \n  .grvsc-line-number {\n    padding: 0 2px;\n    text-align: right;\n    opacity: 0.7;\n  }\n  \n</style>","frontmatter":{"title":"PyTorch: QuickStart 강의요약","desc":"ABOUT PyTorch","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fixed","placeholder":{"fallback":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBP/EABYBAQEBAAAAAAAAAAAAAAAAAAQAAf/aAAwDAQACEAMQAAAB0zUcIZf/xAAWEAEBAQAAAAAAAAAAAAAAAAARACD/2gAIAQEAAQUCIz//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAaEAEAAQUAAAAAAAAAAAAAAAABACAhMYGR/9oACAEBAAE/IRM35G2aP//aAAwDAQACAAMAAAAQRC//xAAWEQADAAAAAAAAAAAAAAAAAAABEBH/2gAIAQMBAT8QoX//xAAVEQEBAAAAAAAAAAAAAAAAAAAQIf/aAAgBAgEBPxCH/8QAGhABAQACAwAAAAAAAAAAAAAAAREAISAxUf/aAAgBAQABPxBk0xewuK3KhcBUEfOH/9k="},"images":{"fallback":{"src":"/static/5edebcc5594767de39f3bc54336a4a58/5d092/pytorch_study.jpg","srcSet":"/static/5edebcc5594767de39f3bc54336a4a58/5d092/pytorch_study.jpg 474w","sizes":"474px"},"sources":[{"srcSet":"/static/5edebcc5594767de39f3bc54336a4a58/35b49/pytorch_study.webp 474w","type":"image/webp","sizes":"474px"}]},"width":474,"height":298}}},"date":"2022-01-21","category":"PyTorch_Study"}}},"pageContext":{"slug":"/blog/pytorch5/"}},
    "staticQueryHashes": ["1840460387"]}