{
    "componentChunkName": "component---src-templates-blog-post-tsx",
    "path": "/blog/deeplearning12/",
    "result": {"data":{"markdownRemark":{"html":"<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 67.48466257668711%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAIBAwX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHbaAQuD//EABkQAAMAAwAAAAAAAAAAAAAAAAABEAITIf/aAAgBAQABBQI6a8XFP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABcQAAMBAAAAAAAAAAAAAAAAABARICH/2gAIAQEABj8CD2P/xAAcEAEAAgIDAQAAAAAAAAAAAAABABEhQRBhkfD/2gAIAQEAAT8hbvcv4RYrJ7iZ15BZx//aAAwDAQACAAMAAAAQE8//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAZEAEBAQEBAQAAAAAAAAAAAAABEQBBIVH/2gAIAQEAAT8QBcov1x2HKElr7NJfWWOe8MEJv//Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/0362d4959f0ab15ee2e1344486373ef4/6aca1/12_1.jpg\"\n        srcset=\"/static/0362d4959f0ab15ee2e1344486373ef4/d2f63/12_1.jpg 163w,\n/static/0362d4959f0ab15ee2e1344486373ef4/c989d/12_1.jpg 325w,\n/static/0362d4959f0ab15ee2e1344486373ef4/6aca1/12_1.jpg 650w,\n/static/0362d4959f0ab15ee2e1344486373ef4/7c09c/12_1.jpg 975w,\n/static/0362d4959f0ab15ee2e1344486373ef4/f8350/12_1.jpg 1237w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3>Practical Issues</h3>\n<p>Training Data를 많이 필요로 한다. 이에 대한 해결책은 데이터를 많이 모으는 것이고 최근 머신러닝을 하는 사람들이 데이터를 많이 모아놓았다는 것.</p>\n<h4>Regularization techinque / data augmentation</h4>\n<p>적은 데이터로부터 많은 데이터를 합성해내는 것</p>\n<h4>Unsupervised / semi-supervised / reinforcement learning</h4>\n<p>정답이 아닌 피드백만으로 진행된다는 점\r\nComputation 을 많이 필요로 한다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.44171779141104%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAMBAgX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHbkuLGB//EABgQAQADAQAAAAAAAAAAAAAAAAEAEBFB/9oACAEBAAEFAu7kAjf/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAWEAADAAAAAAAAAAAAAAAAAAAQIDH/2gAIAQEABj8CFT//xAAZEAADAQEBAAAAAAAAAAAAAAAAARExIUH/2gAIAQEAAT8hd9DhXNFrGdd02Sroklh//9oADAMBAAIAAwAAABDjD//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABsQAQACAgMAAAAAAAAAAAAAAAEAESFBMVFh/9oACAEBAAE/EKHW/CscUVgs1DHZiW+ZgUwyhgE9gtADon//2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/54bc87fad5cc186bfc780e811a703be9/6aca1/12_2.jpg\"\n        srcset=\"/static/54bc87fad5cc186bfc780e811a703be9/d2f63/12_2.jpg 163w,\n/static/54bc87fad5cc186bfc780e811a703be9/c989d/12_2.jpg 325w,\n/static/54bc87fad5cc186bfc780e811a703be9/6aca1/12_2.jpg 650w,\n/static/54bc87fad5cc186bfc780e811a703be9/7c09c/12_2.jpg 975w,\n/static/54bc87fad5cc186bfc780e811a703be9/fb1d2/12_2.jpg 1213w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3>Regularization</h3>\n<p>Boundary가 복잡하면 training data에 대해서는 잘하지만 지금까지 보지 못했던 데이터에 대해서 처리하기 힘들다는 것이었다. <strong>방정식은 적은데 미지수가 많다라고 해석이 가능하다.</strong> 그런  문제를 <strong>ill-posed problem</strong> 이라고 한다. E(W) 의 경우 <strong>Weight에 Constrain을 줘서 많은 학습을 하도록 해야 한다.</strong> norm of Weight 즉, weight에 대한 제약을 주는 것.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 70.5521472392638%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe3cQKP/xAAYEAADAQEAAAAAAAAAAAAAAAAAARETAv/aAAgBAQABBQIpmm31VTVH/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAGRAAAgMBAAAAAAAAAAAAAAAAEBEAAUGR/9oACAEBAAY/Ag7fTs//xAAbEAACAgMBAAAAAAAAAAAAAAAAAREhMUFh0f/aAAgBAQABPyF5fpLg3zJsJok1tnEf/9oADAMBAAIAAwAAABDTD//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EAB4QAQEBAAEEAwAAAAAAAAAAAAERACExQVFhkdHx/9oACAEBAAE/ELCVPHLESV864EViDOGU19fM9j1vwD73/9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/0733f13237cfc79f38e0da4d98c0043f/6aca1/12_3.jpg\"\n        srcset=\"/static/0733f13237cfc79f38e0da4d98c0043f/d2f63/12_3.jpg 163w,\n/static/0733f13237cfc79f38e0da4d98c0043f/c989d/12_3.jpg 325w,\n/static/0733f13237cfc79f38e0da4d98c0043f/6aca1/12_3.jpg 650w,\n/static/0733f13237cfc79f38e0da4d98c0043f/7c09c/12_3.jpg 975w,\n/static/0733f13237cfc79f38e0da4d98c0043f/033f5/12_3.jpg 1195w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3>Transfer Learning</h3>\n<p>전이 학습이라고 표현한다. 한 문제를 학습하는데 있어서의 정보를 다른 쪽으로 적용시키는 것을 말한다. 바둑의 경우 배울 수 있는 테크닉이 장기를 두는데 도움이 될 수 있는가? 에 대한 비유로 말씀하셨다.</p>\n<p>자동차를 인식하는 데이터가 부족한 경우 Neural Network, 대용량 데이터를 쭉 학습한 다음에 중간부의 경우를 새로운 문제에 적용을 시키면 성능이 상당히 좋아진다. 대용량 데이터로 풀 수 있는 문제를 잘 학습시킨 후 Classification Layout을 <strong>내가 풀 수 있는 문제로 바꾼 후 추가 학습을 진행한다면</strong> 효과를 기대할 수 있을 것이다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 64.41717791411043%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAECAwX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHbaiMtD//EABkQAAIDAQAAAAAAAAAAAAAAAAABAhARE//aAAgBAQABBQJiZzRIyv/EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABcQAAMBAAAAAAAAAAAAAAAAABAgQZH/2gAIAQEABj8CF1P/xAAcEAACAgIDAAAAAAAAAAAAAAAAAREhEDFBYcH/2gAIAQEAAT8ho977IK9G1ttyY4kKx//aAAwDAQACAAMAAAAQgM//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAbEAEBAAMAAwAAAAAAAAAAAAABEQAhMRBRkf/aAAgBAQABPxC4qOjczoJv3mra12w1rm9YupLQv2+P/9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/7ce37112f07da4d52be9a1f31421fcc5/6aca1/12_4.jpg\"\n        srcset=\"/static/7ce37112f07da4d52be9a1f31421fcc5/d2f63/12_4.jpg 163w,\n/static/7ce37112f07da4d52be9a1f31421fcc5/c989d/12_4.jpg 325w,\n/static/7ce37112f07da4d52be9a1f31421fcc5/6aca1/12_4.jpg 650w,\n/static/7ce37112f07da4d52be9a1f31421fcc5/7c09c/12_4.jpg 975w,\n/static/7ce37112f07da4d52be9a1f31421fcc5/e5166/12_4.jpg 1200w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3>Internal Covariate Shift</h3>\n<p><strong>밑에서 어떤 분포를 갖고 있다라는 가정</strong>으로 학습을 하게 된다. 그런데 학습이 되는 동안 밑의 Layer들이 학습을 하게 되고 Conversion 된 상태에서의 <strong>분포가 서로 맞지 않아서</strong> 위쪽 layer의 학습효과가 떨어지는 현상을 Intercal Convariate Shift 라고 한다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 57.668711656441715%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAECAwX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHcaZEtD//EABgQAQADAQAAAAAAAAAAAAAAAAEAAhAR/9oACAEBAAEFAuQhQwz/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAWEAADAAAAAAAAAAAAAAAAAAAQIEH/2gAIAQEABj8CFT//xAAbEAEAAgIDAAAAAAAAAAAAAAABACERMRBxof/aAAgBAQABPyHt7EsBm7Odxb0R8f/aAAwDAQACAAMAAAAQwA//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAdEAEBAAEEAwAAAAAAAAAAAAABEQAQITFRYXGB/9oACAEBAAE/EFd37wKSTvKqzYr5ySODxlF2D1p//9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/8bc99d7791ececf5462bff83240ed9db/6aca1/12_5.jpg\"\n        srcset=\"/static/8bc99d7791ececf5462bff83240ed9db/d2f63/12_5.jpg 163w,\n/static/8bc99d7791ececf5462bff83240ed9db/c989d/12_5.jpg 325w,\n/static/8bc99d7791ececf5462bff83240ed9db/6aca1/12_5.jpg 650w,\n/static/8bc99d7791ececf5462bff83240ed9db/7c09c/12_5.jpg 975w,\n/static/8bc99d7791ececf5462bff83240ed9db/cbe08/12_5.jpg 1273w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3>Batch Normalization</h3>\n<p>x의 평균을 빼고 표준편차로 나누게 되는 정규화 과정을 Batch Normalization이라고 한다. <strong>밑 Layer의 Batch를 표준화 시켜주는 과정</strong>이 된다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 66.25766871165644%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAEDBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe4kI0H/xAAaEAACAgMAAAAAAAAAAAAAAAAAARETIjFB/9oACAEBAAEFAulaZGUC1//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABcQAAMBAAAAAAAAAAAAAAAAABARICH/2gAIAQEABj8CD2P/xAAbEAEBAQACAwAAAAAAAAAAAAABEQAhMVFhkf/aAAgBAQABPyFvl9wuqVyfeTyrpjFxnbf/2gAMAwEAAgADAAAAEHPP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAHBABAAMAAgMAAAAAAAAAAAAAAQARITFBgcHR/9oACAEBAAE/ECVQjnF9hSqc8+5uEtuyKpB5acYVQcq7uZ1ne5//2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/16b20a5c5960e7fb8a7133f03b1b2116/6aca1/12_6.jpg\"\n        srcset=\"/static/16b20a5c5960e7fb8a7133f03b1b2116/d2f63/12_6.jpg 163w,\n/static/16b20a5c5960e7fb8a7133f03b1b2116/c989d/12_6.jpg 325w,\n/static/16b20a5c5960e7fb8a7133f03b1b2116/6aca1/12_6.jpg 650w,\n/static/16b20a5c5960e7fb8a7133f03b1b2116/7c09c/12_6.jpg 975w,\n/static/16b20a5c5960e7fb8a7133f03b1b2116/f8350/12_6.jpg 1237w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3>Batch Normalization</h3>\n<p>원래 Internal Covariate Shift를 해결하기 위해서 나온 개념이지만 다른 것에 효과가 있다는 것이 밝혀졋다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 70.5521472392638%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAdtQhkh//8QAGhABAAMAAwAAAAAAAAAAAAAAAgABAxMyQf/aAAgBAQABBQL2+vEFK0Klam0tiZ//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAaEAACAgMAAAAAAAAAAAAAAAAAAREhAhAx/9oACAEBAAY/AtSzg8YdFyf/xAAcEAEAAgEFAAAAAAAAAAAAAAABABEhMVFhcfD/2gAIAQEAAT8hfLlxJd8ZiylXtgiiw1BlZritDdgn/9oADAMBAAIAAwAAABAwz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABwQAQADAAIDAAAAAAAAAAAAAAEAETEhgWHB0f/aAAgBAQABPxC9gvb0e4dAOFNOrlgr1qmmjrDTuGA0YAb7g1tTB98T/9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/85454e85cbd9c54745d29ab80111c27e/6aca1/12_7.jpg\"\n        srcset=\"/static/85454e85cbd9c54745d29ab80111c27e/d2f63/12_7.jpg 163w,\n/static/85454e85cbd9c54745d29ab80111c27e/c989d/12_7.jpg 325w,\n/static/85454e85cbd9c54745d29ab80111c27e/6aca1/12_7.jpg 650w,\n/static/85454e85cbd9c54745d29ab80111c27e/7c09c/12_7.jpg 975w,\n/static/85454e85cbd9c54745d29ab80111c27e/3e6fe/12_7.jpg 1222w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3>ReLU Activation Funciton</h3>\n<p><strong>좋은점</strong></p>\n<ol>\n<li>빠르다. Exponension이 들어가지 않고 maximun 연산 하나이다.</li>\n<li>여러 정보가 하나의 노드에 merge되어 특징이 섞이게 된다. (Hidden Layer)</li>\n</ol>\n<p>Non Zero의 값을 갖는 노드가 적게 유지할 수 있다.\r\n3. 도함수가 0에 가까운 값을 가지지 않기 때문에 영향이 적게 발생한다.\r\n안좋은 점</p>\n<ol>\n<li>Negative한 점에 대해서는 학습이 전혀 이루어지지 않는다.</li>\n<li>Positive 방향에 대해서 Boundary가 없다.</li>\n</ol>\n<p>이렇게 되면 Deep Network와 RNN에서 문제가 발생한다. 수학적으로 Overflow가 발생할 수 있다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 69.93865030674846%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIDBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAd1kCZcP/8QAGBABAQADAAAAAAAAAAAAAAAAARADESH/2gAIAQEAAQUCji2p2f/EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABkQAAEFAAAAAAAAAAAAAAAAAAIQERIgkf/aAAgBAQAGPwJHkW0//8QAHBAAAgICAwAAAAAAAAAAAAAAAREAECExQVGx/9oACAEBAAE/ISFlndOyG+oczPHsayzX/9oADAMBAAIAAwAAABAQz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABsQAQEBAQEAAwAAAAAAAAAAAAERACFBMVGB/9oACAEBAAE/EOVdwSnrrz9mJgF8MBn4YYl56s+9ApIyYaXf/9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/9b66c6e128cb90feec046fa6d2dc1059/6aca1/12_8.jpg\"\n        srcset=\"/static/9b66c6e128cb90feec046fa6d2dc1059/d2f63/12_8.jpg 163w,\n/static/9b66c6e128cb90feec046fa6d2dc1059/c989d/12_8.jpg 325w,\n/static/9b66c6e128cb90feec046fa6d2dc1059/6aca1/12_8.jpg 650w,\n/static/9b66c6e128cb90feec046fa6d2dc1059/7c09c/12_8.jpg 975w,\n/static/9b66c6e128cb90feec046fa6d2dc1059/5ac89/12_8.jpg 1210w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3>Sparse Coding</h3>\n<p>Dimenstion 자체는 클 수 있지만 <strong>작은 Neural 만을 잡아내서 노이지를 없애줄 수 있다.</strong></p>\n<style class=\"grvsc-styles\">\n  .grvsc-container {\n    overflow: auto;\n    position: relative;\n    -webkit-overflow-scrolling: touch;\n    padding-top: 1rem;\n    padding-top: var(--grvsc-padding-top, var(--grvsc-padding-v, 1rem));\n    padding-bottom: 1rem;\n    padding-bottom: var(--grvsc-padding-bottom, var(--grvsc-padding-v, 1rem));\n    border-radius: 8px;\n    border-radius: var(--grvsc-border-radius, 8px);\n    font-feature-settings: normal;\n    line-height: 1.4;\n  }\n  \n  .grvsc-code {\n    display: table;\n  }\n  \n  .grvsc-line {\n    display: table-row;\n    box-sizing: border-box;\n    width: 100%;\n    position: relative;\n  }\n  \n  .grvsc-line > * {\n    position: relative;\n  }\n  \n  .grvsc-gutter-pad {\n    display: table-cell;\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  .grvsc-gutter {\n    display: table-cell;\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter::before {\n    content: attr(data-content);\n  }\n  \n  .grvsc-source {\n    display: table-cell;\n    padding-left: 1.5rem;\n    padding-left: var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem));\n    padding-right: 1.5rem;\n    padding-right: var(--grvsc-padding-right, var(--grvsc-padding-h, 1.5rem));\n  }\n  \n  .grvsc-source:empty::after {\n    content: ' ';\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter + .grvsc-source {\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  /* Line transformer styles */\n  \n  .grvsc-has-line-highlighting > .grvsc-code > .grvsc-line::before {\n    content: ' ';\n    position: absolute;\n    width: 100%;\n  }\n  \n  .grvsc-line-diff-add::before {\n    background-color: var(--grvsc-line-diff-add-background-color, rgba(0, 255, 60, 0.2));\n  }\n  \n  .grvsc-line-diff-del::before {\n    background-color: var(--grvsc-line-diff-del-background-color, rgba(255, 0, 20, 0.2));\n  }\n  \n  .grvsc-line-number {\n    padding: 0 2px;\n    text-align: right;\n    opacity: 0.7;\n  }\n  \n</style>","frontmatter":{"title":"Deep Learning Basic","desc":"Regularization, Transfer learning, Internal Coveriate Shift, Batch Normalization","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fixed","placeholder":{"fallback":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAECBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAE/9oADAMBAAIQAxAAAAHm3C2eoP/EABkQAQACAwAAAAAAAAAAAAAAAAEAAhESIP/aAAgBAQABBQIqs0YmOP/EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABcQAAMBAAAAAAAAAAAAAAAAAAAgITH/2gAIAQEABj8ChhU//8QAGRABAAIDAAAAAAAAAAAAAAAAAQARIDHh/9oACAEBAAE/IdSuC9RFQpw//9oADAMBAAIAAwAAABDED//EABURAQEAAAAAAAAAAAAAAAAAABAh/9oACAEDAQE/EIf/xAAVEQEBAAAAAAAAAAAAAAAAAAAQIf/aAAgBAgEBPxCn/8QAGxABAAEFAQAAAAAAAAAAAAAAATEAEBEhYdH/2gAIAQEAAT8QDYk7CghNHj2k+ISWxy3/2Q=="},"images":{"fallback":{"src":"/static/c131c100e3af8f5788852f15cd55d03c/56315/deeplearning_basic.jpg","srcSet":"/static/c131c100e3af8f5788852f15cd55d03c/56315/deeplearning_basic.jpg 532w","sizes":"532px"},"sources":[{"srcSet":"/static/c131c100e3af8f5788852f15cd55d03c/1239d/deeplearning_basic.webp 532w","type":"image/webp","sizes":"532px"}]},"width":532,"height":363}}},"date":"2022-01-17","category":"Deep Learning"}}},"pageContext":{"slug":"/blog/deeplearning12/"}},
    "staticQueryHashes": ["1840460387"]}