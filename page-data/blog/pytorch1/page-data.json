{
    "componentChunkName": "component---src-templates-blog-post-tsx",
    "path": "/blog/pytorch1/",
    "result": {"data":{"markdownRemark":{"html":"<h1>nn.Module 이해하기</h1>\n<pre class=\"grvsc-container github-light-theme grvsc-ps-t4tStz\" data-language=\"\" data-index=\"0\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\">import torch</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">import math</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">x = torch.linspace(-math.pi, math.pi, 2000)</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">y = torch.sin(x)</span></span></code></pre>\n<h3>sin 함수모형을 예측하기 위해 (-파이,+파이)의 값을 가지는 2000개의 데이터를 활용한다.</h3>\n<h3>단순히 Autograd 함수를 통해서 모델과 손실함수를 정의하는 것이 아니라 nn.Module 을 통해서 사용자 정의 모델 및 손실함수(loss function)을 구현하는 것이 KeyPoint.</h3>\n<hr>\n<pre class=\"grvsc-container github-light-theme grvsc-ps-t4tStz\" data-language=\"\" data-index=\"1\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\">p = torch.tensor([1, 2, 3])</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">xx = x.unsqueeze(-1).pow(p)</span></span></code></pre>\n<h3>xx를 만드는 과정에서 BroadCasting의 개념이 활용되었고 이는 Pytorch Tensor에서 제공하는 자동 Shape 변환 툴로 이해하면 된다.</h3>\n<hr>\n<pre class=\"grvsc-container github-light-theme grvsc-ps-t4tStz\" data-language=\"\" data-index=\"2\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\">model = torch.nn.Sequential(</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">    torch.nn.Linear(3, 1),</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">    torch.nn.Flatten(0, 1)</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">)</span></span></code></pre>\n<h3>nn.Sequential 함수에서 Linear Function을 사용해서 입력으로부터 출력을 계산하고 내부 Tensor에 가중치와 편향을 저장하게 된다.</h3>\n<h3>Flatten Fuction을 통해서 예상 출력값인 y의 shape와 동일하도록 1D Tensor로 펴는 과정을 거친다.</h3>\n<hr>\n<h3>MSE(Mean Square Error) 함수를 이용해서 손실을 계산한다. 그리고 learning_rate는 6/10^6으로 설정하고 학습을 진행한다.</h3>\n<pre class=\"grvsc-container github-light-theme grvsc-ps-t4tStz\" data-language=\"\" data-index=\"3\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\">loss_fn = torch.nn.MSELoss(reduction=&#39;sum&#39;)</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">learning_rate = 1e-6</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">for t in range(2000):</span></span></code></pre>\n<hr>\n<h3>y_pred에 위에서 만든 모델을 이용해서 출력 데이터의 Tensor를 만들게 된다.</h3>\n<pre class=\"grvsc-container github-light-theme grvsc-ps-t4tStz\" data-language=\"\" data-index=\"4\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\">    y_pred = model(xx)</span></span></code></pre>\n<hr>\n<h3>MSE loss function을 이용해서 loss Tensor를 반환한다.</h3>\n<pre class=\"grvsc-container github-light-theme grvsc-ps-t4tStz\" data-language=\"\" data-index=\"5\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\">    loss = loss_fn(y_pred, y)</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">    if t % 100 == 99:</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">        print(t, loss.item())</span></span></code></pre>\n<hr>\n<h3>역전파를 위해서 0으로 초기화를 하고 backward 함수를 통해서 loss에 대한 각 Tensor의 계산을 시킨다. 즉, 학습 가능한 모델의 모든 Tensor를 초기화시킨다.</h3>\n<pre class=\"grvsc-container github-light-theme grvsc-ps-t4tStz\" data-language=\"\" data-index=\"6\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\">    model.zero_grad()</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">    loss.backward()</span></span></code></pre>\n<hr>\n<h3>각 Parameter에 접근해서 learning_rate를 이용한 loss 최신화를 진행한다.</h3>\n<pre class=\"grvsc-container github-light-theme grvsc-ps-t4tStz\" data-language=\"\" data-index=\"7\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\">    with torch.no_grad():</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">        for param in model.parameters():</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">            param -= learning_rate * param.grad</span></span></code></pre>\n<hr>\n<pre class=\"grvsc-container github-light-theme grvsc-ps-t4tStz\" data-language=\"\" data-index=\"8\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\">linear_layer = model[0]</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">print(f&#39;Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3&#39;)</span></span></code></pre>\n<h3>결과값</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 277px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 190.79754601226995%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAmABQDASIAAhEBAxEB/8QAGAABAQEBAQAAAAAAAAAAAAAAAAIBAwX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAH3J3DoCJrCmicDoD//xAAXEAEBAQEAAAAAAAAAAAAAAAABEDEg/9oACAEBAAEFAuTIUpn/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AV//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AV//xAAWEAADAAAAAAAAAAAAAAAAAAABEDD/2gAIAQEABj8CoX//xAAbEAACAgMBAAAAAAAAAAAAAAABEAAhETFBUf/aAAgBAQABPyFDOLnrOlFU6UFbnWv/2gAMAwEAAgADAAAAEGPOMIAP/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPxBf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPxBf/8QAHxAAAgICAgMBAAAAAAAAAAAAAAERITFBUYFhkfDh/9oACAEBAAE/EMt5y0W+Z7KuxDcPLIp1rj8KoQodSawRMqyT7/tilpqdfbMqDkbfYakaUrFH/9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/fa0bde8e9dcc6b3619a15844a6adff7c/d9965/pytorch1.jpg\"\n        srcset=\"/static/fa0bde8e9dcc6b3619a15844a6adff7c/d2f63/pytorch1.jpg 163w,\n/static/fa0bde8e9dcc6b3619a15844a6adff7c/d9965/pytorch1.jpg 277w\"\n        sizes=\"(max-width: 277px) 100vw, 277px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<style class=\"grvsc-styles\">\n  .grvsc-container {\n    overflow: auto;\n    position: relative;\n    -webkit-overflow-scrolling: touch;\n    padding-top: 1rem;\n    padding-top: var(--grvsc-padding-top, var(--grvsc-padding-v, 1rem));\n    padding-bottom: 1rem;\n    padding-bottom: var(--grvsc-padding-bottom, var(--grvsc-padding-v, 1rem));\n    border-radius: 8px;\n    border-radius: var(--grvsc-border-radius, 8px);\n    font-feature-settings: normal;\n    line-height: 1.4;\n  }\n  \n  .grvsc-code {\n    display: table;\n  }\n  \n  .grvsc-line {\n    display: table-row;\n    box-sizing: border-box;\n    width: 100%;\n    position: relative;\n  }\n  \n  .grvsc-line > * {\n    position: relative;\n  }\n  \n  .grvsc-gutter-pad {\n    display: table-cell;\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  .grvsc-gutter {\n    display: table-cell;\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter::before {\n    content: attr(data-content);\n  }\n  \n  .grvsc-source {\n    display: table-cell;\n    padding-left: 1.5rem;\n    padding-left: var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem));\n    padding-right: 1.5rem;\n    padding-right: var(--grvsc-padding-right, var(--grvsc-padding-h, 1.5rem));\n  }\n  \n  .grvsc-source:empty::after {\n    content: ' ';\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter + .grvsc-source {\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  /* Line transformer styles */\n  \n  .grvsc-has-line-highlighting > .grvsc-code > .grvsc-line::before {\n    content: ' ';\n    position: absolute;\n    width: 100%;\n  }\n  \n  .grvsc-line-diff-add::before {\n    background-color: var(--grvsc-line-diff-add-background-color, rgba(0, 255, 60, 0.2));\n  }\n  \n  .grvsc-line-diff-del::before {\n    background-color: var(--grvsc-line-diff-del-background-color, rgba(255, 0, 20, 0.2));\n  }\n  \n  .grvsc-line-number {\n    padding: 0 2px;\n    text-align: right;\n    opacity: 0.7;\n  }\n  \n  .github-light-theme {\n    background-color: #ffffff;\n    color: #000000;\n  }\n  .github-light-theme .grvsc-line-highlighted::before {\n    background-color: var(--grvsc-line-highlighted-background-color, rgba(0, 0, 0, 0.05));\n    box-shadow: inset var(--grvsc-line-highlighted-border-width, 4px) 0 0 0 var(--grvsc-line-highlighted-border-color, rgba(0, 0, 0, 0.2));\n  }\n  body[data-theme=dark] .grvsc-ps-t4tStz { color: #ffffff; }\n  body[data-theme=dark] .grvsc-ps-t4tStz .grvsc-line-highlighted::before {\n    background-color: var(--grvsc-line-highlighted-background-color, rgba(0, 0, 0, 0.05));\n    box-shadow: inset var(--grvsc-line-highlighted-border-width, 4px) 0 0 0 var(--grvsc-line-highlighted-border-color, rgba(0, 0, 0, 0.2));\n  }\n</style>","frontmatter":{"title":"PyTorch: nn Module","desc":"nn.Module","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fixed","placeholder":{"fallback":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBP/EABYBAQEBAAAAAAAAAAAAAAAAAAQAAf/aAAwDAQACEAMQAAAB0zUcIZf/xAAWEAEBAQAAAAAAAAAAAAAAAAARACD/2gAIAQEAAQUCIz//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAaEAEAAQUAAAAAAAAAAAAAAAABACAhMYGR/9oACAEBAAE/IRM35G2aP//aAAwDAQACAAMAAAAQRC//xAAWEQADAAAAAAAAAAAAAAAAAAABEBH/2gAIAQMBAT8QoX//xAAVEQEBAAAAAAAAAAAAAAAAAAAQIf/aAAgBAgEBPxCH/8QAGhABAQACAwAAAAAAAAAAAAAAAREAISAxUf/aAAgBAQABPxBk0xewuK3KhcBUEfOH/9k="},"images":{"fallback":{"src":"/static/5edebcc5594767de39f3bc54336a4a58/5d092/pytorch_study.jpg","srcSet":"/static/5edebcc5594767de39f3bc54336a4a58/5d092/pytorch_study.jpg 474w","sizes":"474px"},"sources":[{"srcSet":"/static/5edebcc5594767de39f3bc54336a4a58/35b49/pytorch_study.webp 474w","type":"image/webp","sizes":"474px"}]},"width":474,"height":298}}},"date":"2022-01-20","category":"PyTorch_Study"}}},"pageContext":{"slug":"/blog/pytorch1/"}},
    "staticQueryHashes": ["1840460387"]}